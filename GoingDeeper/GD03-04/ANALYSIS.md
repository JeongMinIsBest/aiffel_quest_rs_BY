# 로이터 뉴스 분류 모델 성능 분석 보고서

---

## 1. 실험 개요

본 실험은 로이터 뉴스 데이터셋을 분류하기 위해, **다양한 Vocabulary 크기**와 **8가지 머신러닝 모델** 및 **1개의 딥러닝 모델**을 조합하여 최적의 솔루션을 찾고. `reuters.load_data`의 `num_words` 파라미터를 `[1000, 5000, 10000, 20000, None(전체)]`으로 변경하며 각 조건에서 8개 머신러닝 모델의 정확도를 측정하고, 그 중 최적의 조건으로 딥러닝 모델과 성능을 비교 분석

## 2. 머신러닝 모델 실험 결과

| Vocabulary Size | MultinomialNB | ComplementNB | LogisticRegression | LinearSVC | DecisionTree | RandomForest | GradientBoosting | **VotingClassifier** |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1000 | 0.6834 | 0.7342 | 0.7524 | 0.7008 | 0.6118 | 0.7012 | 0.7511 | 0.7685 |
| 5000 | 0.6692 | 0.7703 | 0.8059 | 0.7743 | 0.6113 | 0.6963 | 0.7573 | 0.8143 |
| 10000 | 0.6509 | 0.7716 | 0.8081 | 0.7881 | 0.6086 | 0.6683 | 0.7551 | 0.8085 |
| **20000** | 0.6100 | 0.7676 | 0.8099 | 0.7898 | 0.6082 | 0.6554 | 0.7685 | **`0.8206`** |
| All Words | 0.5926 | 0.7582 | 0.8108 | 0.7890 | 0.6131 | 0.6732 | 0.7671 | 0.8183 |

## 3. 머신러닝 모델 분석

### 3.1. 최적 솔루션 도출
- 5가지의 단어 수 조건과 8가지 머신러닝 모델을 조합하여 실험한 결과, **Vocabulary Size를 20,000개로 설정**했을 때 **VotingClassifier** 모델이 **약 82.1%**의 가장 높은 정확도를 기록하며 최적의 솔루션임을 확인
- `VotingClassifier`는 여러 모델(로지스틱 회귀, 나이브 베이즈, 그래디언트 부스팅)의 예측을 종합하는 앙상블 기법의 장점을 살려, 대부분의 조건에서 가장 안정적이고 높은 성능을 보임


### 3.2. Vocabulary Size에 따른 성능 변화 분석
- **Sweet Spot의 발견**: 모든 단어를 사용했을 때보다 **20,000개로 단어 수를 제한했을 때 성능이 더 높았다**는 점이 가장 흥미로웠고, 이는 상위 20,000개를 넘어선 매우 희귀한 단어들은 학습에 유용한 정보로 작용하기 보다, 모델 학습을 방해하는 **노이즈(Noise)로 작용**한 것으로 보임. `num_words=20000` 설정이 일종의 **특성 선택(Feature Selection)** 역할을 하여 최적의 성능을 이끌어 낸 것으로 추정
- **모델별 특성 분석**:
    - **나이브 베이즈 계열**: 데이터 불균형에 더 강건한 `ComplementNB`가 `MultinomialNB`보다 일관되게 높은 성능을 보임. 특히 `MultinomialNB`는 단어 수가 늘어날수록 성능이 하락했는데, 이는 앞에서 말한 것 처럼 단어가 늘어날 수록 노이즈 특성에 민감하게 반응하기 때문으로 분석.
    - **선형 모델 계열**: `LogisticRegression`과 `LinearSVC`는 고차원의 희소 데이터(TF-IDF)를 잘 처리하여 안정적으로 높은 성능을 유지
    - **트리 기반 모델**: `DecisionTree`와 `RandomForest`는 모든 조건에서 성능이 가장 낮았음. 트리 기반 모델이 수만 개의 차원을 가진 TF-IDF 행렬과 같은 고차원 희소 데이터에 대해 패턴을 효과적으로 학습하기 어려운 특성이 있는 것으로 보임. 트리들은 결국에 자르는 기준을 찾아야 하는데 TF-IDF 같은 희소 데이터 (0으로 대부분 채워진 데이터)에서는 기준점을 정하기 어려운 점이 가장 안맞는 포인트였던 것으로 보임

---

## 4. 머신러닝 vs. 딥러닝 최종 비교

머신러닝 실험에서 도출된 최적의 조건 (`num_words=20000`)을 동일하게 적용하여, `VotingClassifier`와 두 종류의 딥러닝 모델(`1D-CNN`, `Bi-LSTM`) 성능을 비교했다.

### 4.1. 최종 비교 결과

| 모델 종류 | 모델명 | 정확도 (Accuracy) |
| :--- | :--- | :--- |
| **머신러닝** | **VotingClassifier** | **`0.8206`** |
| 딥러닝 | PyTorch 1D-CNN | `0.7907` |
| 딥러닝 | PyTorch Bi-LSTM | `0.6541` |

**결과**: 실험 결과, **머신러닝 앙상블 모델이 모든 딥러닝 모델보다 높은 성능**을 보였다. 하지만 딥러닝 모델 중에서는 **1D-CNN이 Bi-LSTM보다 약 13.6%p 더 높은 성능**을 기록하며, 머신러닝 모델과의 격차를 크게 줄임

> **실험 결과 한줄 요약**: "잘 차려진 밥상(TF-IDF)의 머신러닝"이, '스스로 밭은 갈았지만 좋은 농기구(1D-CNN)를 쓴 딥러닝'과 '맨손으로 밭을 간 딥러닝(Bi-LSTM)'을 모두 이김

### 4.2. 성능 차이 원인 분석

- **1. 왜 머신러닝이 딥러닝을 이겼는가? (TF-IDF의 효율성)**
  - 머신러닝 모델은 **TF-IDF**를 사용하여 뉴스 주제를 판별하는 '핵심 키워드' 정보를 명확하게 학습했고, 그 결과가 그대로 나온 것으로 보인다. 반면, 딥러닝 모델들은 사전 학습 없이 한정된 데이터만으로 단어의 의미와 패턴을 처음부터 학습해야 했기에, 잘 정제된 특징을 사용한 머신러닝을 넘어서기 어려웠음

- **2. 왜 1D-CNN이 Bi-LSTM보다 훨씬 나았는가? (문제와 모델의 궁합)**
  - **1D-CNN**은 문장 내에서 '핵심 단어 조합(n-gram)'을 찾아내는 데 특화된 모델로 '주제 분류' 문제의 핵심(특정 단어들의 등장 여부)을 정확히 공략하는 방식
  - 반면 **Bi-LSTM**은 문장 전체의 '순서와 문맥'을 파악하는 데 강점이 있지만, 이 문제에서는 강점이 오히려 덜 중요했고, 결과적으로 문제의 특성과 더 잘 맞는 아키텍처를 가진 1D-CNN이 훨씬 높은 성능을 보였음

- **3. 딥러닝의 공통적인 한계 (데이터의 양)**
  - 두 딥러닝 모델은 약 9,000개의 훈련 샘플만으로 20,000개 단어에 대한 복잡한 관계를 학습해야 했으며, 이는 딥러닝의 잠재력을 충분히 발휘하기에는 부족한 데이터량으로 판단
  - 반면, 머신러닝 모델은 상대적으로 적은 데이터에서도 안정적인 성능을 유지하며, 특히 선형 모델과 앙상블 기법이 효과적


## 5. 최종 결론

본 프로젝트를 통해 로이터 뉴스 분류 문제에서는 **VotingClassifier 앙상블 모델**과 **20,000개의 단어 수를 조합**하는 것이 **약 82.1%**의 정확도로 최적의 솔루션임을 도출

또한, 딥러닝 모델을 사용할 경우, **문제의 특성에 맞는 아키텍처를 선택하는 것이 얼마나 중요한지** 확인할 수 있는 문제였고, 문맥보다 키워드가 중요한 이 문제에서는 Bi-LSTM보다 **1D-CNN이 훨씬 더 효과적**이었음

묻지도 따지지도 않고 최신 기술이라고 항상 최고는 아니며, 주어진 데이터와 문제의 특성을 이해하고 그에 맞는 최적의 도구를 선택하는 것이 가장 중요하다는 것으로 최종 결론을 내리면 되겠다.

---

## 6. 참고 노트북

- **Vocabulary Size 비교 실험**:
  - [`news_classification_vocab_size.ipynb`](./news_classification_vocab_size.ipynb)
- **머신러닝 vs. Bi-LSTM 비교**:
  - [`news_classification_ml_vs_dl_v1.ipynb`](./news_classification_ml_vs_dl_v1.ipynb)
- **머신러닝 vs. 1D-CNN 비교**:
  - [`news_classification_ml_vs_dl_v2.ipynb`](./news_classification_ml_vs_dl_v2.ipynb)
