{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "QYaSRcpvpXSv",
   "metadata": {
    "id": "QYaSRcpvpXSv"
   },
   "source": [
    "# 한-영 번역기 만들기 (v5.1: Transformer 최종 수정)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e884e8",
   "metadata": {},
   "source": [
    "## Step 1. 라이브러리 설치 및 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21NDjbbpX-U",
   "metadata": {
    "id": "b21NDjbbpX-U"
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# !apt-get install -y fonts-nanum\n",
    "\n",
    "# !pip install Korpora\n",
    "# !git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "# !ls\n",
    "# %cd Mecab-ko-for-Google-Colab/\n",
    "# !bash install_mecab-ko_on_colab_light_220429.sh\n",
    "\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "IwV-hav5pXSx",
   "metadata": {
    "id": "IwV-hav5pXSx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 폰트: NanumBarunGothic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
    "\n",
    "fontpath = \"/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\"\n",
    "fontprop = fm.FontProperties(fname=fontpath, size=12)\n",
    "plt.rcParams[\"font.family\"] = fontprop.get_name()\n",
    "\n",
    "print(f\"설정된 폰트: {fontprop.get_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003034d",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 준비 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "GeOE8yNgpXSy",
   "metadata": {
    "id": "GeOE8yNgpXSy"
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "train_kor_path = os.path.join(data_dir, 'korean-english-park.train.ko')\n",
    "train_eng_path = os.path.join(data_dir, 'korean-english-park.train.en')\n",
    "dev_kor_path = os.path.join(data_dir, 'korean-english-park.dev.ko')\n",
    "dev_eng_path = os.path.join(data_dir, 'korean-english-park.dev.en')\n",
    "test_kor_path = os.path.join(data_dir, 'korean-english-park.test.ko')\n",
    "test_eng_path = os.path.join(data_dir, 'korean-english-park.test.en')\n",
    "\n",
    "with open(train_kor_path, \"r\") as f: train_kor_raw = f.read().splitlines()\n",
    "with open(train_eng_path, \"r\") as f: train_eng_raw = f.read().splitlines()\n",
    "with open(dev_kor_path, \"r\") as f: dev_kor_raw = f.read().splitlines()\n",
    "with open(dev_eng_path, \"r\") as f: dev_eng_raw = f.read().splitlines()\n",
    "with open(test_kor_path, \"r\") as f: test_kor_raw = f.read().splitlines()\n",
    "with open(test_eng_path, \"r\") as f: test_eng_raw = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "llV56qmlpXSy",
   "metadata": {
    "id": "llV56qmlpXSy"
   },
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "spacy_eng = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_corpus(kor_sentence, eng_sentence):\n",
    "    kor_sentence = kor_sentence.lower().strip()\n",
    "    eng_sentence = eng_sentence.lower().strip()\n",
    "    kor_sentence = re.sub(r\"[^가-힣?.!,]+\", \" \", kor_sentence)\n",
    "    eng_sentence = re.sub(r\"([?.!,])\", r\" \\1 \", eng_sentence)\n",
    "    eng_sentence = re.sub(r'[^a-zA-Z?.!,]+', ' ', eng_sentence)\n",
    "    eng_sentence = re.sub(r'\\s+', ' ', eng_sentence)\n",
    "    return kor_sentence, eng_sentence.strip()\n",
    "\n",
    "def tokenize_corpus(kor_raw, eng_raw, max_len=40):\n",
    "    kor_corpus, eng_corpus = [], []\n",
    "    cleaned_corpus = list(set(zip(kor_raw, eng_raw)))\n",
    "    for kor, eng in cleaned_corpus:\n",
    "        kor_prep, eng_prep = preprocess_corpus(kor, eng)\n",
    "        kor_tokens = mecab.morphs(kor_prep)\n",
    "        eng_tokens_raw = [token.text for token in spacy_eng.tokenizer(eng_prep)]\n",
    "        eng_tokens = ['<start>'] + eng_tokens_raw + ['<end>']\n",
    "        if len(kor_tokens) <= max_len and len(eng_tokens) <= max_len:\n",
    "            kor_corpus.append(kor_tokens)\n",
    "            eng_corpus.append(eng_tokens)\n",
    "    return kor_corpus, eng_corpus\n",
    "\n",
    "train_kor_corpus, train_eng_corpus = tokenize_corpus(train_kor_raw, train_eng_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "N1DpPAH-pXSz",
   "metadata": {
    "id": "N1DpPAH-pXSz"
   },
   "outputs": [],
   "source": [
    "def build_vocab(corpus, max_vocab_size=10000):\n",
    "    counter = Counter()\n",
    "    for sentence in corpus:\n",
    "        counter.update(sentence)\n",
    "    vocab = counter.most_common(max_vocab_size - 4)\n",
    "    word_to_idx = {word: i+4 for i, (word, _) in enumerate(vocab)}\n",
    "    word_to_idx['<pad>'] = 0\n",
    "    word_to_idx['<unk>'] = 1\n",
    "    word_to_idx['<start>'] = 2\n",
    "    word_to_idx['<end>'] = 3\n",
    "    idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "# build_vocab 함수에 전달하는 max_vocab_size는 모델의 VOCAB_SIZE와 일치해야 합니다.\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "kor_word_to_idx, kor_idx_to_word = build_vocab(train_kor_corpus, MAX_VOCAB_SIZE)\n",
    "eng_word_to_idx, eng_idx_to_word = build_vocab(train_eng_corpus, MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yXO0wqIGpXSz",
   "metadata": {
    "id": "yXO0wqIGpXSz"
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(corpus, word_to_idx):\n",
    "    sequences = []\n",
    "    for sentence in corpus:\n",
    "        sequence = [word_to_idx.get(word, word_to_idx['<unk>']) for word in sentence]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "dev_kor_corpus, dev_eng_corpus = [], []\n",
    "for kor, eng in zip(dev_kor_raw, dev_eng_raw):\n",
    "    kor_prep, eng_prep = preprocess_corpus(kor, eng)\n",
    "    kor_tokens = mecab.morphs(kor_prep)\n",
    "    eng_tokens_raw = [token.text for token in spacy_eng.tokenizer(eng_prep)]\n",
    "    eng_tokens = ['<start>'] + eng_tokens_raw + ['<end>']\n",
    "    dev_kor_corpus.append(kor_tokens)\n",
    "    dev_eng_corpus.append(eng_tokens)\n",
    "\n",
    "test_kor_corpus, test_eng_corpus = [], []\n",
    "for kor, eng in zip(test_kor_raw, test_eng_raw):\n",
    "    kor_prep, eng_prep = preprocess_corpus(kor, eng)\n",
    "    kor_tokens = mecab.morphs(kor_prep)\n",
    "    eng_tokens_raw = [token.text for token in spacy_eng.tokenizer(eng_prep)]\n",
    "    eng_tokens = ['<start>'] + eng_tokens_raw + ['<end>']\n",
    "    test_kor_corpus.append(kor_tokens)\n",
    "    test_eng_corpus.append(eng_tokens)\n",
    "\n",
    "train_kor_sequences = text_to_sequence(train_kor_corpus, kor_word_to_idx)\n",
    "train_eng_sequences = text_to_sequence(train_eng_corpus, eng_word_to_idx)\n",
    "dev_kor_sequences = text_to_sequence(dev_kor_corpus, kor_word_to_idx)\n",
    "dev_eng_sequences = text_to_sequence(dev_eng_corpus, eng_word_to_idx)\n",
    "test_kor_sequences = text_to_sequence(test_kor_corpus, kor_word_to_idx)\n",
    "test_eng_sequences = text_to_sequence(test_eng_corpus, eng_word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3jKO9r0kpXS0",
   "metadata": {
    "id": "3jKO9r0kpXS0"
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sequences, trg_sequences):\n",
    "        self.src_sequences = src_sequences\n",
    "        self.trg_sequences = trg_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.src_sequences[idx]), torch.tensor(self.trg_sequences[idx])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        src_batch.append(src_sample)\n",
    "        trg_batch.append(trg_sample)\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=kor_word_to_idx['<pad>'])\n",
    "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=eng_word_to_idx['<pad>'])\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = TranslationDataset(train_kor_sequences, train_eng_sequences)\n",
    "valid_dataset = TranslationDataset(dev_kor_sequences, dev_eng_sequences)\n",
    "test_dataset = TranslationDataset(test_kor_sequences, test_eng_sequences)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddVnh-BHpXS0",
   "metadata": {
    "id": "ddVnh-BHpXS0"
   },
   "source": [
    "## Step 3. 트랜스포머 모델 설계 (수정된 최종 버전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "jeewAUTTpXS0",
   "metadata": {
    "id": "jeewAUTTpXS0"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2) * (-math.log(10000.0) / emb_size))\n",
    "        position = torch.arange(maxlen).unsqueeze(1)\n",
    "        pos_embedding = torch.zeros(maxlen, emb_size)\n",
    "        pos_embedding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_embedding[:, 1::2] = torch.cos(position * div_term)\n",
    "        pos_embedding = pos_embedding.unsqueeze(0)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers, num_decoder_layers, emb_size, nhead, src_vocab_size, tgt_vocab_size, dim_feedforward, dropout):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None, src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tzzCFrAYpXS1",
   "metadata": {
    "id": "tzzCFrAYpXS1"
   },
   "source": [
    "## Step 4. 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hfg_NfTfpXS1",
   "metadata": {
    "id": "hfg_NfTfpXS1"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 (v5.1 수정)\n",
    "# 단어 사전 최대 크기를 상수로 정의\n",
    "VOCAB_SIZE = 10000\n",
    "SRC_VOCAB_SIZE = VOCAB_SIZE\n",
    "TGT_VOCAB_SIZE = VOCAB_SIZE\n",
    "\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델 초기화 시, 고정된 단어 사전 크기를 전달\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM, 0.1)\n",
    "model = transformer.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=eng_word_to_idx['<pad>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oBMOpNvJpXS1",
   "metadata": {
    "id": "oBMOpNvJpXS1"
   },
   "source": [
    "### 학습 및 평가 함수 정의 (트랜스포머용, v5.1 수정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gNMvjudCpXS1",
   "metadata": {
    "id": "gNMvjudCpXS1"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = None  # 인코더는 마스크 필요 없음\n",
    "\n",
    "    src_padding_mask = (src == kor_word_to_idx['<pad>'])\n",
    "    tgt_padding_mask = (tgt == eng_word_to_idx['<pad>'])\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
    "\n",
    "def train_epoch(model, iterator, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    progress_bar = tqdm(iterator, desc=\"Training...\")\n",
    "    for src, tgt in progress_bar:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:, :-1]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    return losses / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    progress_bar = tqdm(iterator, desc=\"Evaluating...\")\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in progress_bar:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "\n",
    "            tgt_input = tgt[:, :-1]\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "            logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "            tgt_out = tgt[:, 1:]\n",
    "            loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            losses += loss.item()\n",
    "\n",
    "    return losses / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3ErzuOEpXS2",
   "metadata": {
    "id": "q3ErzuOEpXS2"
   },
   "source": [
    "### 학습 루프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Lst0-2qapXS2",
   "metadata": {
    "id": "Lst0-2qapXS2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/987 [00:00<?, ?it/s]/opt/conda/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.65it/s, loss=5.78]\n",
      "Evaluating...:   0%|          | 0/16 [00:00<?, ?it/s]/opt/conda/lib/python3.12/site-packages/torch/nn/modules/transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 44.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 6.135, Val loss: 5.610, Epoch time = 52.935s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.90it/s, loss=5.28]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 47.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 5.554, Val loss: 5.288, Epoch time = 52.222s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.80it/s, loss=5.3] \n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 5.304, Val loss: 5.099, Epoch time = 52.509s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.85it/s, loss=5.27]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 5.129, Val loss: 4.955, Epoch time = 52.372s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.85it/s, loss=4.94]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 4.992, Val loss: 4.852, Epoch time = 52.352s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.84it/s, loss=4.56]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 4.877, Val loss: 4.764, Epoch time = 52.391s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.83it/s, loss=4.6] \n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 4.777, Val loss: 4.684, Epoch time = 52.406s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.82it/s, loss=4.65]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 4.689, Val loss: 4.618, Epoch time = 52.457s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.84it/s, loss=4.47]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 49.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 4.609, Val loss: 4.558, Epoch time = 52.379s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.84it/s, loss=4.45]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 4.536, Val loss: 4.509, Epoch time = 52.381s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.85it/s, loss=4.29]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 4.468, Val loss: 4.462, Epoch time = 52.378s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.86it/s, loss=4.65]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 4.407, Val loss: 4.426, Epoch time = 52.344s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.82it/s, loss=4.51]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 49.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 4.348, Val loss: 4.388, Epoch time = 52.437s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.80it/s, loss=4.49]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 4.294, Val loss: 4.355, Epoch time = 52.501s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.84it/s, loss=4.15]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 47.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 4.241, Val loss: 4.318, Epoch time = 52.394s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.86it/s, loss=4.13]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 49.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 4.192, Val loss: 4.297, Epoch time = 52.326s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.87it/s, loss=4.14]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 48.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 4.145, Val loss: 4.272, Epoch time = 52.302s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.86it/s, loss=4.4] \n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 49.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 4.100, Val loss: 4.244, Epoch time = 52.345s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.87it/s, loss=4.11]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 47.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 4.057, Val loss: 4.230, Epoch time = 52.300s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 987/987 [00:52<00:00, 18.85it/s, loss=3.68]\n",
      "Evaluating...: 100%|██████████| 16/16 [00:00<00:00, 49.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 4.017, Val loss: 4.198, Epoch time = 52.364s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(model, train_loader, optimizer)\n",
    "    end_time = time.time()\n",
    "    valid_loss = evaluate(model, valid_loader)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'translator-ko-en-v5.1-transformer.pt')\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {valid_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faSfaHv5pXS3",
   "metadata": {
    "id": "faSfaHv5pXS3"
   },
   "source": [
    "## Step 5. 최종 테스트 및 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "LqwBeflMpXS3",
   "metadata": {
    "id": "LqwBeflMpXS3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating...: 100%|██████████| 32/32 [00:00<00:00, 47.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.244 | Test PPL:  69.703 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('translator-ko-en-v5.1-transformer.pt'))\n",
    "test_loss = evaluate(model, test_loader)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "KvWyehpvpXS3",
   "metadata": {
    "id": "KvWyehpvpXS3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 오바마는 대통령이다.\n",
      "Translated:  obama is the president . \n",
      "\n",
      "Original: 시민들은 도시 속에 산다.\n",
      "Translated:  they are <unk> in the city of <unk> . \n",
      "\n",
      "Original: 커피는 필요 없다.\n",
      "Translated:  it s not clear how many people do . \n",
      "\n",
      "Original: 일곱 명의 사망자가 발생했다.\n",
      "Translated:  the death toll from the death toll in the country s death toll\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(1)).type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        # out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == eng_word_to_idx['<end>']:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model, src_sentence):\n",
    "    model.eval()\n",
    "    src_tokens = mecab.morphs(src_sentence)\n",
    "    src_tensor = torch.LongTensor([kor_word_to_idx.get(t, kor_word_to_idx['<unk>']) for t in src_tokens]).unsqueeze(0).to(device)\n",
    "    num_tokens = src_tensor.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool) # This should be None, but passing for greedy_decode\n",
    "    tgt_tokens = greedy_decode(model, src_tensor, src_mask, max_len=num_tokens + 5, start_symbol=eng_word_to_idx['<start>']).flatten()\n",
    "    return \" \".join([eng_idx_to_word.get(tok.item(), '<unk>') for tok in tgt_tokens]).replace(\"<start>\", \"\").replace(\"<end>\", \"\")\n",
    "\n",
    "example_sentences = [\n",
    "    \"오바마는 대통령이다.\",\n",
    "    \"시민들은 도시 속에 산다.\",\n",
    "    \"커피는 필요 없다.\",\n",
    "    \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "for sentence in example_sentences:\n",
    "    print(f'Original: {sentence}')\n",
    "    print(f\"Translated: {translate(model, sentence)}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
