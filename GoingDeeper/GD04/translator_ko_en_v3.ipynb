{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "QYaSRcpvpXSv",
   "metadata": {
    "id": "QYaSRcpvpXSv"
   },
   "source": [
    "# 한-영 번역기 만들기 (v3: Attention Map 시각화 추가)\n",
    "---\n",
    "## Step 1. 데이터 준비 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21NDjbbpX-U",
   "metadata": {
    "id": "b21NDjbbpX-U"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -y fonts-nanum\n",
    "\n",
    "# !pip install Korpora\n",
    "# !git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "# !ls\n",
    "# %cd Mecab-ko-for-Google-Colab/\n",
    "# !bash install_mecab-ko_on_colab_light_220429.sh\n",
    "\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IwV-hav5pXSx",
   "metadata": {
    "id": "IwV-hav5pXSx"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from konlpy.tag import Mecab\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
    "\n",
    "fontpath = \"/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\"\n",
    "fontprop = fm.FontProperties(fname=fontpath, size=12)\n",
    "plt.rcParams[\"font.family\"] = fontprop.get_name()\n",
    "\n",
    "print(f\"설정된 폰트: {fontprop.get_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DTDwumwvpXSy",
   "metadata": {
    "id": "DTDwumwvpXSy"
   },
   "source": [
    "### 데이터 불러오기 (train, dev, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GeOE8yNgpXSy",
   "metadata": {
    "id": "GeOE8yNgpXSy"
   },
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "train_kor_path = os.path.join(data_dir, 'korean-english-park.train.ko')\n",
    "train_eng_path = os.path.join(data_dir, 'korean-english-park.train.en')\n",
    "dev_kor_path = os.path.join(data_dir, 'korean-english-park.dev.ko')\n",
    "dev_eng_path = os.path.join(data_dir, 'korean-english-park.dev.en')\n",
    "test_kor_path = os.path.join(data_dir, 'korean-english-park.test.ko')\n",
    "test_eng_path = os.path.join(data_dir, 'korean-english-park.test.en')\n",
    "\n",
    "with open(train_kor_path, \"r\") as f: train_kor_raw = f.read().splitlines()\n",
    "with open(train_eng_path, \"r\") as f: train_eng_raw = f.read().splitlines()\n",
    "with open(dev_kor_path, \"r\") as f: dev_kor_raw = f.read().splitlines()\n",
    "with open(dev_eng_path, \"r\") as f: dev_eng_raw = f.read().splitlines()\n",
    "with open(test_kor_path, \"r\") as f: test_kor_raw = f.read().splitlines()\n",
    "with open(test_eng_path, \"r\") as f: test_eng_raw = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BWKiVHHwpXSy",
   "metadata": {
    "id": "BWKiVHHwpXSy"
   },
   "source": [
    "### 전처리 및 토큰화 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llV56qmlpXSy",
   "metadata": {
    "id": "llV56qmlpXSy"
   },
   "outputs": [],
   "source": [
    "# Mecab 형태소 분석기 초기화 (한국어 토크나이즈용)\n",
    "mecab = Mecab()\n",
    "\n",
    "def preprocess_corpus(kor_sentence, eng_sentence):\n",
    "    \"\"\"\n",
    "    한국어와 영어 문장을 정제하는 함수.\n",
    "    한국어: 소문자 변환, 한글과 기본 구두점만 남김\n",
    "    영어: 소문자 변환, 구두점 앞뒤에 공백 추가, 알파벳과 기본 구두점만 남김, '<start>'와 '<end>' 토큰 추가\n",
    "\n",
    "    Args:\n",
    "        kor_sentence (str): 한국어 원문 문장\n",
    "        eng_sentence (str): 영어 원문 문장\n",
    "\n",
    "    Returns:\n",
    "        kor_sentence (str): 정제된 한국어 문장\n",
    "        eng_sentence (str): 정제된 영어 문장 (시작/종료 토큰 포함)\n",
    "    \"\"\"\n",
    "    # 한국어 전처리: 소문자 변환, 양쪽 공백 제거, 한글과 기본 구두점만 남김\n",
    "    kor_sentence = kor_sentence.lower().strip()\n",
    "    kor_sentence = re.sub(r\"[^가-힣?.!,]+\", \" \", kor_sentence)  # 한글과 '?.!,' 이외의 문자 제거\n",
    "\n",
    "    # 영어 전처리: 소문자 변환, 양쪽 공백 제거\n",
    "    eng_sentence = eng_sentence.lower().strip()\n",
    "    # 구두점 앞뒤에 공백 추가 (예: \"hello!\" → \"hello !\")\n",
    "    eng_sentence = re.sub(r\"([?.!,])\", r\" \\1 \", eng_sentence)\n",
    "    # 알파벳과 기본 구두점만 남김\n",
    "    eng_sentence = re.sub(r'[^a-zA-Z?.!,]+', ' ', eng_sentence)\n",
    "    # 연속 공백을 단일 공백으로 대체\n",
    "    eng_sentence = re.sub(r'\\s+', ' ', eng_sentence)\n",
    "    # 시작과 종료 토큰 추가\n",
    "    eng_sentence = '<start> ' + eng_sentence.strip() + ' <end>'\n",
    "\n",
    "    return kor_sentence, eng_sentence\n",
    "\n",
    "def tokenize_corpus(kor_raw, eng_raw, max_len=40):\n",
    "    \"\"\"\n",
    "    병렬 코퍼스를 토크나이즈하고, 길이가 max_len 이하인 쌍만 선택하는 함수.\n",
    "\n",
    "    Args:\n",
    "        kor_raw (list): 한국어 원문 문장 리스트\n",
    "        eng_raw (list): 영어 원문 문장 리스트\n",
    "        max_len (int): 최대 허용 토큰 길이 (기본값: 40)\n",
    "\n",
    "    Returns:\n",
    "        kor_corpus (list): 토크나이즈된 한국어 문장 리스트\n",
    "        eng_corpus (list): 토크나이즈된 영어 문장 리스트\n",
    "    \"\"\"\n",
    "    kor_corpus, eng_corpus = [], []\n",
    "    # 중복 제거를 위해 set 사용 (zip으로 병렬 쌍 유지)\n",
    "    cleaned_corpus = list(set(zip(kor_raw, eng_raw)))\n",
    "    for kor, eng in cleaned_corpus:\n",
    "        # 문장 정제\n",
    "        kor_prep, eng_prep = preprocess_corpus(kor, eng)\n",
    "        # 한국어: Mecab으로 형태소 분석\n",
    "        kor_tokens = mecab.morphs(kor_prep)\n",
    "        # 영어: 공백 기준으로 토크나이즈\n",
    "        eng_tokens = eng_prep.split()\n",
    "        # 길이가 max_len 이하인 쌍만 추가\n",
    "        if len(kor_tokens) <= max_len and len(eng_tokens) <= max_len:\n",
    "            kor_corpus.append(kor_tokens)\n",
    "            eng_corpus.append(eng_tokens)\n",
    "    return kor_corpus, eng_corpus\n",
    "\n",
    "# 훈련 데이터 토크나이즈\n",
    "train_kor_corpus, train_eng_corpus = tokenize_corpus(train_kor_raw, train_eng_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muzLTknjpXSz",
   "metadata": {
    "id": "muzLTknjpXSz"
   },
   "source": [
    "### 단어 사전 구축 (Train set 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N1DpPAH-pXSz",
   "metadata": {
    "id": "N1DpPAH-pXSz"
   },
   "outputs": [],
   "source": [
    "def build_vocab(corpus, max_vocab_size=10000):\n",
    "    \"\"\"\n",
    "    코퍼스로부터 단어 사전을 구축하고, 단어-인덱스 매핑을 생성하는 함수.\n",
    "\n",
    "    Args:\n",
    "        corpus (list of list): 토크나이즈된 문장 리스트 (예: [['안녕', '세계'], ['안녕', '친구']])\n",
    "        max_vocab_size (int): 최대 단어 사전 크기 (기본값: 10000)\n",
    "\n",
    "    Returns:\n",
    "        word_to_idx (dict): 단어에서 인덱스로의 매핑 (예: {'안녕': 4, '세계': 5, ...})\n",
    "        idx_to_word (dict): 인덱스에서 단어로의 매핑 (예: {4: '안녕', 5: '세계', ...})\n",
    "\n",
    "    Note:\n",
    "        - 인덱스 0: '<pad>' (패딩 토큰)\n",
    "        - 인덱스 1: '<unk>' (알 수 없는 단어 토큰)\n",
    "        - 인덱스 2: '<start>' (시작 토큰)\n",
    "        - 인덱스 3: '<end>' (종료 토큰)\n",
    "        - 나머지 인덱스(4 이상): 실제 단어\n",
    "    \"\"\"\n",
    "    counter = Counter()\n",
    "    for sentence in corpus:\n",
    "        # 코퍼스 내 모든 단어의 빈도수 계산\n",
    "        counter.update(sentence)\n",
    "\n",
    "    # 가장 빈도가 높은 단어 상위 (max_vocab_size - 4)개 선택\n",
    "    vocab = counter.most_common(max_vocab_size - 4)\n",
    "\n",
    "    # 단어-인덱스 매핑 생성 (인덱스 4부터 시작)\n",
    "    word_to_idx = {word: i+4 for i, (word, _) in enumerate(vocab)}\n",
    "\n",
    "    # 특수 토큰의 인덱스 할당\n",
    "    word_to_idx['<pad>'] = 0    # 패딩 토큰\n",
    "    word_to_idx['<unk>'] = 1    # 알 수 없는 단어 토큰\n",
    "    word_to_idx['<start>'] = 2  # 시작 토큰\n",
    "    word_to_idx['<end>'] = 3    # 종료 토큰\n",
    "\n",
    "    # 인덱스-단어 매핑 생성 (word_to_idx의 역매핑)\n",
    "    idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "# 한국어와 영어 단어 사전 구축\n",
    "kor_word_to_idx, kor_idx_to_word = build_vocab(train_kor_corpus)\n",
    "eng_word_to_idx, eng_idx_to_word = build_vocab(train_eng_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TvWwCC8ApXSz",
   "metadata": {
    "id": "TvWwCC8ApXSz"
   },
   "source": [
    "### 모든 데이터셋을 숫자 시퀀스로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yXO0wqIGpXSz",
   "metadata": {
    "id": "yXO0wqIGpXSz"
   },
   "outputs": [],
   "source": [
    "def text_to_sequence(corpus, word_to_idx):\n",
    "    \"\"\"\n",
    "    텍스트 코퍼스를 단어 인덱스 시퀀스로 변환하는 함수.\n",
    "\n",
    "    Args:\n",
    "        corpus (list of list): 토크나이즈된 문장 리스트 (예: [['안녕', '세계'], ['안녕', '친구']])\n",
    "        word_to_idx (dict): 단어와 인덱스를 매핑한 사전 (예: {'안녕': 4, '세계': 5, ...})\n",
    "\n",
    "    Returns:\n",
    "        sequences (list of list): 각 문장을 인덱스 시퀀스로 변환한 리스트 (예: [[4, 5], [4, 6]])\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for sentence in corpus:\n",
    "        # 각 단어에 대해 사전에서 인덱스를 찾고, 없으면 '<unk>'(1)의 인덱스로 대체\n",
    "        sequence = [word_to_idx.get(word, word_to_idx['<unk>']) for word in sentence]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "# 개발(validation) 데이터 전처리\n",
    "dev_kor_corpus, dev_eng_corpus = [], []\n",
    "for kor, eng in zip(dev_kor_raw, dev_eng_raw):\n",
    "    # 한글과 영어 문장을 전처리 (소문자 변환, 특수문자 처리, 토크나이즈)\n",
    "    kor_prep, eng_prep = preprocess_corpus(kor, eng)\n",
    "    # 한글은 Mecab으로 토크나이즈, 영어는 split()으로 토크나이즈\n",
    "    dev_kor_corpus.append(mecab.morphs(kor_prep))\n",
    "    dev_eng_corpus.append(eng_prep.split())\n",
    "\n",
    "# 테스트 데이터 전처리\n",
    "test_kor_corpus, test_eng_corpus = [], []\n",
    "for kor, eng in zip(test_kor_raw, test_eng_raw):\n",
    "    kor_prep, eng_prep = preprocess_corpus(kor, eng)\n",
    "    test_kor_corpus.append(mecab.morphs(kor_prep))\n",
    "    test_eng_corpus.append(eng_prep.split())\n",
    "\n",
    "# 훈련, 개발, 테스트 데이터 모두 단어 인덱스 시퀀스로 변환\n",
    "train_kor_sequences = text_to_sequence(train_kor_corpus, kor_word_to_idx)\n",
    "train_eng_sequences = text_to_sequence(train_eng_corpus, eng_word_to_idx)\n",
    "dev_kor_sequences = text_to_sequence(dev_kor_corpus, kor_word_to_idx)\n",
    "dev_eng_sequences = text_to_sequence(dev_eng_corpus, eng_word_to_idx)\n",
    "test_kor_sequences = text_to_sequence(test_kor_corpus, kor_word_to_idx)\n",
    "test_eng_sequences = text_to_sequence(test_eng_corpus, eng_word_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dAoh_XNOpXS0",
   "metadata": {
    "id": "dAoh_XNOpXS0"
   },
   "source": [
    "## Step 2. 모델 설계 및 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3jKO9r0kpXS0",
   "metadata": {
    "id": "3jKO9r0kpXS0"
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    번역 데이터를 PyTorch Dataset으로 변환하는 클래스.\n",
    "    src_sequences(원문)와 trg_sequences(번역문)을 텐서로 변환하여 반환합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, src_sequences, trg_sequences):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src_sequences (list): 원문 시퀀스 리스트 (예: 한국어 인덱스 시퀀스)\n",
    "            trg_sequences (list): 번역문 시퀀스 리스트 (예: 영어 인덱스 시퀀스)\n",
    "        \"\"\"\n",
    "        self.src_sequences = src_sequences\n",
    "        self.trg_sequences = trg_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"데이터셋의 총 샘플 수 반환\"\"\"\n",
    "        return len(self.src_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        주어진 인덱스의 샘플을 텐서로 변환하여 반환\n",
    "\n",
    "        Args:\n",
    "            idx (int): 샘플 인덱스\n",
    "\n",
    "        Returns:\n",
    "            src_sample (torch.Tensor): 원문 시퀀스 텐서\n",
    "            trg_sample (torch.Tensor): 번역문 시퀀스 텐서\n",
    "        \"\"\"\n",
    "        return torch.tensor(self.src_sequences[idx]), torch.tensor(self.trg_sequences[idx])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    배치 내 샘플을 패딩하여 동일한 길이로 맞추는 함수.\n",
    "    pad_sequence를 사용하여 배치 내 가장 긴 시퀀스에 맞춰 패딩을 추가합니다.\n",
    "\n",
    "    Args:\n",
    "        batch (list): (src_sample, trg_sample) 튜플 리스트\n",
    "\n",
    "    Returns:\n",
    "        src_padded (torch.Tensor): 패딩된 원문 배치 텐서\n",
    "        trg_padded (torch.Tensor): 패딩된 번역문 배치 텐서\n",
    "    \"\"\"\n",
    "    src_batch, trg_batch = [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        src_batch.append(src_sample)\n",
    "        trg_batch.append(trg_sample)\n",
    "    # 배치 내 시퀀스를 가장 긴 길이에 맞춰 패딩 (한국어: '<pad>'=0, 영어: '<pad>'=0)\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=kor_word_to_idx['<pad>'])\n",
    "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=eng_word_to_idx['<pad>'])\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "# 배치 크기 설정\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Dataset 및 DataLoader 생성\n",
    "train_dataset = TranslationDataset(train_kor_sequences, train_eng_sequences)\n",
    "valid_dataset = TranslationDataset(dev_kor_sequences, dev_eng_sequences)\n",
    "test_dataset = TranslationDataset(test_kor_sequences, test_eng_sequences)\n",
    "\n",
    "# DataLoader: 배치 단위로 데이터 로딩, 학습 데이터는 shuffle 적용\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,  # 학습 데이터는 에포크마다 순서 섞기\n",
    "    collate_fn=collate_fn  # 배치 패딩 함수 지정\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddVnh-BHpXS0",
   "metadata": {
    "id": "ddVnh-BHpXS0"
   },
   "source": [
    "### Attention 기반 Seq2Seq 모델 설계 (Attention 값 반환 기능 추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jeewAUTTpXS0",
   "metadata": {
    "id": "jeewAUTTpXS0"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=kor_word_to_idx['<pad>'])\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "\n",
    "        # hidden: [n_layers * 2, batch_size, hidden_dim]\n",
    "        # (forward_L1, backward_L1, forward_L2, backward_L2, ...) 순서\n",
    "\n",
    "        # 정방향과 역방향의 은닉 상태를 각 레이어별로 합쳐서 디코더의 은닉 상태로 만듭니다.\n",
    "        # (n_layers * 2, batch, hid_dim) -> (n_layers, batch, hid_dim * 2) -> fc -> (n_layers, batch, hid_dim)\n",
    "        hidden = hidden.view(self.n_layers, 2, -1, self.hidden_dim)\n",
    "        hidden = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=2)\n",
    "        hidden = torch.tanh(self.fc(hidden))\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bahdanau 어텐션 메커니즘.\n",
    "    (양방향 인코더에 맞춰 입력 크기 수정)\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # W2는 양방향 인코더의 출력을 받으므로 입력 크기가 hidden_dim * 2\n",
    "        self.W2 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, query, values):\n",
    "        # query (디코더 은닉 상태): (배치 크기, hidden_dim)\n",
    "        # values (인코더 출력): (배치 크기, src_len, hidden_dim * 2)\n",
    "        query = query.unsqueeze(1)\n",
    "\n",
    "        score = self.V(torch.tanh(self.W1(query) + self.W2(values)))\n",
    "\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "        return context_vector, attention_weights.squeeze(-1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=eng_word_to_idx['<pad>'])\n",
    "        self.rnn = nn.GRU((hidden_dim * 2) + emb_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        # 어텐션 계산 시 query는 최상위 레이어의 hidden state를 사용합니다.\n",
    "        context_vector, attention_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "\n",
    "        context_vector = context_vector.unsqueeze(1)\n",
    "        rnn_input = torch.cat((embedded, context_vector), dim=2)\n",
    "\n",
    "        # GRU에 hidden state를 그대로 전달합니다. (모양이 맞으므로 unsqueeze/squeeze 불필요)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, attention_weights\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Seq2Seq 모델.\n",
    "    인코더와 디코더를 결합하여 번역을 수행합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src (torch.Tensor): 원문 시퀀스 (배치 크기, 시퀀스 길이)\n",
    "            trg (torch.Tensor): 번역문 시퀀스 (배치 크기, 시퀀스 길이)\n",
    "            teacher_forcing_ratio (float): Teacher Forcing 비율\n",
    "\n",
    "        Returns:\n",
    "            outputs (torch.Tensor): 예측 시퀀스 (배치 크기, 시퀀스 길이, 출력 단어 사전 크기)\n",
    "            attentions (torch.Tensor): 어텐션 가중치 (배치 크기, 시퀀스 길이, 원문 시퀀스 길이)\n",
    "        \"\"\"\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        src_len = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # 예측과 어텐션 가중치를 저장할 텐서 초기화\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        attentions = torch.zeros(batch_size, trg_len, src_len).to(self.device)\n",
    "        # 인코더 처리\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        # 디코더의 첫 입력: '<start>' 토큰 (trg[:, 0])\n",
    "        input = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            # 디코더 스텝: 예측, 은닉 상태, 어텐션 가중치 계산\n",
    "            output, hidden, attention = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            attentions[:, t, :] = attention\n",
    "            # Teacher Forcing: 확률에 따라 실제 다음 단어 또는 예측 단어 사용\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "        return outputs, attentions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tzzCFrAYpXS1",
   "metadata": {
    "id": "tzzCFrAYpXS1"
   },
   "source": [
    "## Step 3. 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hfg_NfTfpXS1",
   "metadata": {
    "id": "hfg_NfTfpXS1"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "VOCAB_SIZE = 10000\n",
    "INPUT_DIM = VOCAB_SIZE      # 한국어 단어 사전 크기 (인코더 입력 차원)\n",
    "OUTPUT_DIM = VOCAB_SIZE     # 영어 단어 사전 크기 (디코더 출력 차원)\n",
    "ENC_EMB_DIM = 256                     # 인코더 임베딩 차원\n",
    "DEC_EMB_DIM = 256                     # 디코더 임베딩 차원\n",
    "HID_DIM = 256                         # GRU 은닉 상태 차원\n",
    "N_LAYERS = 1                          # GRU 레이어 수\n",
    "ENC_DROPOUT = 0.6                     # 인코더 드롭아웃 비율\n",
    "DEC_DROPOUT = 0.6                     # 디코더 드롭아웃 비율\n",
    "\n",
    "# 디바이스 설정: MPS(Apple Silicon) 사용 가능 시 MPS, 아니면 CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 어텐션 메커니즘 초기화\n",
    "attn = BahdanauAttention(HID_DIM)\n",
    "\n",
    "# 인코더와 디코더 초기화\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
    "\n",
    "# Seq2Seq 모델 초기화 및 디바이스 할당\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "# 옵티마이저: AdamW 사용\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "\n",
    "# 손실 함수: CrossEntropyLoss, '<pad>' 토큰은 무시 (ignore_index=eng_word_to_idx['<pad>'])\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=eng_word_to_idx['<pad>'],\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "# 학습률 스케줄러 정의\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oBMOpNvJpXS1",
   "metadata": {
    "id": "oBMOpNvJpXS1"
   },
   "source": [
    "### 학습 및 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gNMvjudCpXS1",
   "metadata": {
    "id": "gNMvjudCpXS1"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \"\"\"\n",
    "    모델을 한 에포크 동안 학습시키는 함수.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Seq2Seq 모델\n",
    "        iterator (DataLoader): 학습 데이터 로더\n",
    "        optimizer: 옵티마이저 (예: Adam)\n",
    "        criterion: 손실 함수 (예: CrossEntropyLoss)\n",
    "        clip (float): 그레이디언트 클리핑 값\n",
    "\n",
    "    Returns:\n",
    "        epoch_loss (float): 평균 에포크 손실\n",
    "    \"\"\"\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    epoch_loss = 0\n",
    "    # 진행 상황 표시를 위한 tqdm 진척 바\n",
    "    progress_bar = tqdm(iterator, desc=\"Training\", leave=False)\n",
    "\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        src, trg = batch\n",
    "        src, trg = src.long().to(device), trg.long().to(device) # 배치 데이터를 디바이스로 이동\n",
    "\n",
    "        optimizer.zero_grad()  # 그레이디언트 초기화\n",
    "\n",
    "        # 모델 예측 (어텐션은 무시)\n",
    "        output, _ = model(src, trg)\n",
    "\n",
    "        # 출력과 타겟 텐서 변형:\n",
    "        # [배치 크기, 시퀀스 길이, 출력 차원] → [배치 크기 * (시퀀스 길이 - 1), 출력 차원]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)  # '<start>' 토큰 이후부터 사용\n",
    "        trg = trg[:, 1:].reshape(-1)  # '<start>' 토큰 이후부터 사용\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        loss.backward()\n",
    "        # 그레이디언트 클리핑 (exploding gradient 방지)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실 누적 및 진척 바 업데이트\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # 평균 에포크 손실 반환\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \"\"\"\n",
    "    모델을 평가하는 함수 (검증/테스트용).\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Seq2Seq 모델\n",
    "        iterator (DataLoader): 평가 데이터 로더\n",
    "        criterion: 손실 함수 (예: CrossEntropyLoss)\n",
    "\n",
    "    Returns:\n",
    "        epoch_loss (float): 평균 에포크 손실\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():  # 그레이디언트 계산 비활성화\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src, trg = batch\n",
    "            src, trg = src.long().to(device), trg.long().to(device)  # 배치 데이터를 디바이스로 이동\n",
    "\n",
    "            # 모델 예측 (teacher forcing 비활성화, 어텐션 무시)\n",
    "            output, _ = model(src, trg, 0)\n",
    "\n",
    "            # 출력과 타겟 텐서 변형:\n",
    "            # [배치 크기, 시퀀스 길이, 출력 차원] → [배치 크기 * (시퀀스 길이 - 1), 출력 차원]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)  # '<start>' 토큰 이후부터 사용\n",
    "            trg = trg[:, 1:].reshape(-1)  # '<start>' 토큰 이후부터 사용\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    # 평균 에포크 손실 반환\n",
    "    return epoch_loss / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3ErzuOEpXS2",
   "metadata": {
    "id": "q3ErzuOEpXS2"
   },
   "source": [
    "### 학습 루프 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df35ef-f5bd-4ffc-b556-6c52b5d912aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \"\"\"\n",
    "    어텐션 맵을 히트맵으로 시각화하는 함수.\n",
    "    Args:\n",
    "        sentence (list): 원문 토큰 리스트 (한국어)\n",
    "        translation (list): 번역문 토큰 리스트 (영어)\n",
    "        attention (numpy.ndarray): 어텐션 가중치 행렬\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # 어텐션 텐서를 numpy 배열로 변환\n",
    "    attention = attention.cpu().detach().numpy()  # (시퀀스 길이, 원문 길이)\n",
    "\n",
    "    # 어텐션 맵 히트맵 그리기 (viridis 컬러맵 사용)\n",
    "    cax = ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    # x축 설정\n",
    "    ax.set_xticks(range(len(sentence) + 3))  # '<start>' + sentence + '<end>'\n",
    "    ax.set_xticklabels([''] + ['<start>'] + [t for t in sentence] + ['<end>'], rotation=90)\n",
    "\n",
    "    # y축 설정 (tick 위치 명시적으로 지정)\n",
    "    ax.set_yticks(range(len(translation) + 1))  # '' + translation\n",
    "    ax.set_yticklabels([''] + translation)\n",
    "\n",
    "    ax.tick_params(labelsize=12)\n",
    "\n",
    "    # 축 눈금 간격 설정\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate_and_show_attention(sentence, model, kor_word_to_idx, eng_idx_to_word, device, max_len=50):\n",
    "    \"\"\"\n",
    "    입력 문장을 번역하고 어텐션 맵을 시각화하는 함수.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): 번역할 한국어 문장\n",
    "        model (nn.Module): Seq2Seq 모델\n",
    "        kor_word_to_idx (dict): 한국어 단어-인덱스 매핑\n",
    "        eng_idx_to_word (dict): 영어 인덱스-단어 매핑\n",
    "        device: 디바이스 (CPU/GPU/MPS)\n",
    "        max_len (int): 최대 번역 길이\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "\n",
    "    # 입력 문장 토크나이즈 및 텐서 변환\n",
    "    tokens = mecab.morphs(sentence)\n",
    "    src_indexes = [kor_word_to_idx.get(t, kor_word_to_idx['<unk>']) for t in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    # 인코더 처리\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "\n",
    "    # 번역 시작: '<start>' 토큰으로 초기화\n",
    "    trg_indexes = [eng_word_to_idx['<start>']]\n",
    "    attentions = torch.zeros(max_len, len(src_indexes)).to(device)  # (max_len, src_len) 2D로 초기화\n",
    "\n",
    "    # 디코딩 루프\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "\n",
    "        # 어텐션 가중치 저장\n",
    "        attentions[i] = attention.squeeze(0)  # (1, 원문 길이) → (원문 길이,)로 변환\n",
    "\n",
    "        # 다음 단어 예측\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        # '<end>' 토큰을 만나면 종료\n",
    "        if pred_token == eng_word_to_idx['<end>']:\n",
    "            break\n",
    "\n",
    "    # 인덱스를 단어로 변환\n",
    "    trg_tokens = [eng_idx_to_word.get(i, '<unk>') for i in trg_indexes]\n",
    "\n",
    "    # '<start>'와 '<end>' 토큰 제거\n",
    "    translation = trg_tokens[1:-1]\n",
    "\n",
    "    # 원문과 번역문 출력\n",
    "    print(f'Original: {sentence}')\n",
    "    print(f\"Translated: {' '.join(translation)}\")\n",
    "\n",
    "    # 어텐션 맵 시각화\n",
    "    display_attention(tokens, translation, attentions[:len(translation)])  # 2D 행렬로 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Lst0-2qapXS2",
   "metadata": {
    "id": "Lst0-2qapXS2"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "N_EPOCHS = 100  # 최대 에포크 수 (Early Stopping으로 조기 종료됨)\n",
    "CLIP = 1      # 그레이디언트 클리핑 값\n",
    "PATIENCE = 3    # Early Stopping을 위한 patience (검증 손실이 개선되지 않는 에포크 수)\n",
    "\n",
    "# 최적의 검증 손실 초기화\n",
    "best_valid_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "attention_check_sentence = \"오바마는 대통령이다.\"\n",
    "\n",
    "# 에포크별 학습 루프\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 학습 및 검증 손실 계산\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    # 검증 손실을 기반으로 학습률 조정\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "\n",
    "    # 검증 손실이 개선된 경우\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'translator-ko-en-v3.pt')\n",
    "        patience_counter = 0\n",
    "        print(f\"  * Best Val. Loss updated: {best_valid_loss:.3f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  * Early Stopping Counter: {patience_counter}/{PATIENCE}\")\n",
    "\n",
    "    # Early Stopping 조건 확인\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\n[Early Stopping] Validation loss did not improve for {PATIENCE} epochs. Stopping training...\")\n",
    "        break\n",
    "\n",
    "    # 현재 학습률 가져오기\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # 에포크별 결과 출력\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.0f}s')\n",
    "    # 학습률 출력\n",
    "    print(f'\\tCurrent LR: {current_lr:.6f}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')\n",
    "\n",
    "    print(\"\\n--- Checking Attention Map ---\")\n",
    "        \n",
    "    translate_and_show_attention(\n",
    "        attention_check_sentence,\n",
    "        model,\n",
    "        kor_word_to_idx,\n",
    "        eng_idx_to_word,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faSfaHv5pXS3",
   "metadata": {
    "id": "faSfaHv5pXS3"
   },
   "source": [
    "## Step 4. 최종 테스트 및 번역 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LqwBeflMpXS3",
   "metadata": {
    "id": "LqwBeflMpXS3"
   },
   "outputs": [],
   "source": [
    "# 저장된 최적 모델 가중치 로드\n",
    "model.load_state_dict(torch.load('translator-ko-en-v3.pt'))\n",
    "\n",
    "# 테스트 데이터로 모델 평가\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "\n",
    "# 테스트 손실과 Perplexity 출력\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_beam_search(sentence, model, kor_word_to_idx, eng_idx_to_word, device, beam_width=5, max_len=50):\n",
    "    model.eval()\n",
    "    tokens = mecab.morphs(sentence)\n",
    "    src_indexes = [kor_word_to_idx.get(t, kor_word_to_idx['<unk>']) for t in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "\n",
    "    # 초기 후보 시퀀스: ['<start>'] + 확률(1.0)\n",
    "    sequences = [[eng_word_to_idx['<start>']],]\n",
    "    sequence_probs = [1.0]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        all_candidates = []\n",
    "        for seq, prob in zip(sequences, sequence_probs):\n",
    "            trg_tensor = torch.LongTensor([seq[-1]]).to(device)\n",
    "            with torch.no_grad():\n",
    "                output, hidden, _ = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "            top_k = torch.topk(output, beam_width, dim=1)\n",
    "            for i in range(beam_width):\n",
    "                next_token = top_k.indices[0][i].item()\n",
    "                next_prob = torch.log(torch.softmax(top_k.values[0][i], dim=0)).item()\n",
    "                candidate_seq = seq + [next_token]\n",
    "                candidate_prob = prob + next_prob\n",
    "                all_candidates.append((candidate_seq, candidate_prob))\n",
    "\n",
    "        # 상위 beam_width개 후보만 유지\n",
    "        sequences, sequence_probs = zip(*sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width])\n",
    "        sequences, sequence_probs = list(sequences), list(sequence_probs)\n",
    "\n",
    "        # 모든 후보가 '<end>'로 끝나면 종료\n",
    "        if all(seq[-1] == eng_word_to_idx['<end>'] for seq in sequences):\n",
    "            break\n",
    "\n",
    "    # 가장 확률이 높은 시퀀스 선택\n",
    "    best_sequence = sequences[0]\n",
    "    translation = [eng_idx_to_word.get(i, '<unk>') for i in best_sequence[1:-1]]  # '<start>'와 '<end>' 제거\n",
    "    return ' '.join(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KvWyehpvpXS3",
   "metadata": {
    "id": "KvWyehpvpXS3"
   },
   "outputs": [],
   "source": [
    "# 예문 번역 및 어텐션 시각화\n",
    "example_sentences = [\n",
    "    \"오바마는 대통령이다.\",\n",
    "    \"시민들은 도시 속에 산다.\",\n",
    "    \"커피는 필요 없다.\",\n",
    "    \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "for sentence in example_sentences:\n",
    "    translate_and_show_attention(sentence, model, kor_word_to_idx, eng_idx_to_word, device)\n",
    "    translate_with_beam_search(sentence, model, kor_word_to_idx, eng_idx_to_word, device)\n",
    "    print()  # 예문별 구분선\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "goingdeeper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
