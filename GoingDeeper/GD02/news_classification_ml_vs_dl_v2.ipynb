{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로이터 뉴스 분류: 머신러닝 vs. 딥러닝(1D-CNN) 모델 성능 비교\n",
    "\n",
    "## 목표\n",
    "- [이전 실험](./news_classification_vocab_size.ipynb)에서 찾은 최적의 머신러닝 모델(`VotingClassifier`)과 PyTorch로 구현한 딥러닝 모델(`1D-CNN`)의 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 최적 조건 설정 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 20000\n",
      "Full Train samples: 8982\n",
      "Test samples: 2246\n"
     ]
    }
   ],
   "source": [
    "OPTIMAL_NUM_WORDS = 20000\n",
    "MAX_LEN = 300\n",
    "\n",
    "(x_train_full, y_train_full), (x_test, y_test) = reuters.load_data(num_words=OPTIMAL_NUM_WORDS, test_split=0.2)\n",
    "\n",
    "print(f'Vocabulary Size: {OPTIMAL_NUM_WORDS}')\n",
    "print(f'Full Train samples: {len(x_train_full)}')\n",
    "print(f'Test samples: {len(x_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 비교 실험 1: 최적의 머신러닝 모델 (VotingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VotingClassifier...\n",
      "VotingClassifier 최종 정확도: 0.8206\n"
     ]
    }
   ],
   "source": [
    "x_train_str = [' '.join(map(str, doc)) for doc in x_train_full]\n",
    "x_test_str = [' '.join(map(str, doc)) for doc in x_test]\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'[0-9]+').fit(x_train_str)\n",
    "x_train_dtm = vectorizer.transform(x_train_str)\n",
    "x_test_dtm = vectorizer.transform(x_test_str)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test_dtm)\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2', max_iter=3000)),\n",
    "         ('cb', ComplementNB()),\n",
    "         ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "        ], voting='soft', n_jobs=-1)\n",
    "\n",
    "print('Training VotingClassifier...')\n",
    "voting_classifier.fit(x_train_tfidf, y_train_full)\n",
    "predicted = voting_classifier.predict(x_test_tfidf)\n",
    "ml_accuracy = accuracy_score(y_test, predicted)\n",
    "print(f'VotingClassifier 최종 정확도: {ml_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 비교 실험 2: PyTorch 딥러닝 모델 (1D-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# 1. Device 설정 (MPS 가속)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# 2. 데이터 패딩 및 Tensor 변환\n",
    "x_train_pad = pad_sequences(x_train_full, maxlen=MAX_LEN)\n",
    "x_test_pad = pad_sequences(x_test, maxlen=MAX_LEN)\n",
    "\n",
    "# 3. Train / Validation 분리\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_pad, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. DataLoader 생성\n",
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "val_data = TensorDataset(torch.from_numpy(x_val), torch.from_numpy(y_val))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 1D-CNN 모델 정의\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim, \n",
    "                      out_channels=n_filters, \n",
    "                      kernel_size=fs) \n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.permute(0, 2, 1) # Conv1d는 (N, C, L) 입력을 받음\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 2.2458 | Val Loss: 1.7329 | Val Acc: 0.6082\n",
      "Epoch 2/15 | Train Loss: 1.7040 | Val Loss: 1.4230 | Val Acc: 0.6834\n",
      "Epoch 3/15 | Train Loss: 1.4343 | Val Loss: 1.2875 | Val Acc: 0.6845\n",
      "Epoch 4/15 | Train Loss: 1.2788 | Val Loss: 1.1605 | Val Acc: 0.7407\n",
      "Epoch 5/15 | Train Loss: 1.1256 | Val Loss: 1.1060 | Val Acc: 0.7457\n",
      "Epoch 6/15 | Train Loss: 1.0319 | Val Loss: 1.0122 | Val Acc: 0.7713\n",
      "Epoch 7/15 | Train Loss: 0.9542 | Val Loss: 0.9974 | Val Acc: 0.7685\n",
      "Epoch 8/15 | Train Loss: 0.9021 | Val Loss: 0.9343 | Val Acc: 0.7791\n",
      "Epoch 9/15 | Train Loss: 0.8313 | Val Loss: 0.9063 | Val Acc: 0.7941\n",
      "Epoch 10/15 | Train Loss: 0.7734 | Val Loss: 0.8857 | Val Acc: 0.7935\n",
      "Epoch 11/15 | Train Loss: 0.7074 | Val Loss: 0.8748 | Val Acc: 0.7958\n",
      "Epoch 12/15 | Train Loss: 0.6692 | Val Loss: 0.8949 | Val Acc: 0.7947\n",
      "Epoch 13/15 | Train Loss: 0.6096 | Val Loss: 0.8868 | Val Acc: 0.7947\n",
      "Epoch 14/15 | Train Loss: 0.5556 | Val Loss: 0.8692 | Val Acc: 0.8152\n",
      "Epoch 15/15 | Train Loss: 0.5254 | Val Loss: 0.8625 | Val Acc: 0.8036\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수, 옵티마이저 정의\n",
    "EMBEDDING_DIM = 128\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3, 4, 5]\n",
    "OUTPUT_DIM = 46 # 로이터 뉴스의 카테고리 수\n",
    "DROPOUT = 0.5\n",
    "\n",
    "model = CNNClassifier(OPTIMAL_NUM_WORDS, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # 검증 데이터로 평가\n",
    "    model.eval()\n",
    "    val_loss, val_corrects = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "    print(f'Epoch {epoch+1}/{epochs} | Train Loss: {epoch_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_corrects.float()/len(val_data):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 1D-CNN 최종 정확도: 0.7907\n"
     ]
    }
   ],
   "source": [
    "# 최종 평가\n",
    "model.eval()\n",
    "test_corrects = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).long()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "dl_accuracy = test_corrects.float() / len(test_data)\n",
    "print(f'PyTorch 1D-CNN 최종 정확도: {dl_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 최종 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 최적 머신러닝 모델 (VotingClassifier) 정확도: 0.8206\n",
      "- 딥러닝 모델 (PyTorch 1D-CNN) 정확도: 0.7907\n",
      ">> 머신러닝 앙상블 모델이 더 높은 성능을 보였습니다.\n"
     ]
    }
   ],
   "source": [
    "print(f'- 최적 머신러닝 모델 (VotingClassifier) 정확도: {ml_accuracy:.4f}')\n",
    "print(f'- 딥러닝 모델 (PyTorch 1D-CNN) 정확도: {dl_accuracy:.4f}')\n",
    "\n",
    "if dl_accuracy > ml_accuracy:\n",
    "    print('>> 딥러닝 모델이 더 높은 성능을 보였습니다.')\n",
    "else:\n",
    "    print('>> 머신러닝 앙상블 모델이 더 높은 성능을 보였습니다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goingdeeper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
